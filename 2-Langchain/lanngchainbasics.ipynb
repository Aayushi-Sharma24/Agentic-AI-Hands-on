{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all api key in env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=os.getenv(\"LANGCHAIN_TRACING_V2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Agentic AI** refers to artificial intelligence systems that possess agency—the capacity to act independently, make autonomous decisions, set goals, and influence their environment to achieve desired outcomes. Unlike traditional AI systems, which primarily execute predefined instructions or follow specific algorithms, agentic AI is characterized by its ability to operate with a higher degree of independence and adaptability in dynamic and complex environments.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. **Autonomy**: Agentic AI can perform tasks without constant human supervision, making decisions based on its programming and environmental inputs.\n",
      "\n",
      "2. **Goal-Oriented Behavior**: These AI systems can set, pursue, and adjust goals based on changing circumstances or new information.\n",
      "\n",
      "3. **Adaptability**: They can learn from experiences, adapt to new situations, and modify their behavior accordingly.\n",
      "\n",
      "4. **Perception and Interaction**: Agentic AI often includes advanced capabilities for sensing and interpreting its environment, as well as interacting with humans and other systems effectively.\n",
      "\n",
      "5. **Decision-Making**: Equipped with sophisticated reasoning abilities, agentic AI can evaluate options and choose actions that best align with its objectives.\n",
      "\n",
      "### Examples and Applications\n",
      "\n",
      "- **Autonomous Vehicles**: Self-driving cars navigate complex traffic scenarios, make real-time decisions, and adapt to changing road conditions without human intervention.\n",
      "  \n",
      "- **Robotics**: Advanced robots in manufacturing, healthcare, or service industries perform tasks autonomously, adjusting their actions based on sensory input and task requirements.\n",
      "  \n",
      "- **Intelligent Personal Assistants**: Systems like advanced versions of virtual assistants can manage schedules, prioritize tasks, and make recommendations tailored to user preferences and behaviors.\n",
      "  \n",
      "- **Adaptive Cybersecurity Systems**: These AI systems can detect and respond to cyber threats in real-time, adapting their defenses as new vulnerabilities emerge.\n",
      "\n",
      "### Distinction from Traditional AI\n",
      "\n",
      "Traditional AI often relies on predefined rules and supervised learning, where human input is significant in guiding the AI's actions and decision-making processes. In contrast, agentic AI incorporates elements of unsupervised learning, reinforcement learning, and other advanced methodologies that enable it to operate with greater independence and adaptability.\n",
      "\n",
      "### Ethical and Societal Considerations\n",
      "\n",
      "The development and deployment of agentic AI raise several important ethical and societal issues:\n",
      "\n",
      "- **Accountability**: Determining responsibility for the actions of autonomous AI systems can be complex, especially in cases of malfunction or unintended consequences.\n",
      "\n",
      "- **Control and Alignment**: Ensuring that agentic AI systems' goals and behaviors align with human values and societal norms is crucial to prevent adverse outcomes.\n",
      "\n",
      "- **Transparency**: Understanding how agentic AI makes decisions is essential for trust and accountability, necessitating advancements in explainable AI.\n",
      "\n",
      "- **Impact on Employment**: Autonomous systems may displace certain jobs, leading to economic and workforce challenges that need to be addressed.\n",
      "\n",
      "### Current State and Future Directions\n",
      "\n",
      "As of my knowledge cutoff in October 2023, agentic AI is an active area of research and development. Advances in machine learning, particularly in reinforcement learning and deep learning, have significantly contributed to enhancing the autonomy and decision-making capabilities of AI systems. However, achieving true agency—where AI can independently set and modify complex goals in alignment with human values—remains a challenging endeavor.\n",
      "\n",
      "Research is focusing on:\n",
      "\n",
      "- **Improving Learning Algorithms**: Developing more efficient and adaptable learning methods to enhance AI’s decision-making processes.\n",
      "\n",
      "- **Safety and Alignment**: Creating frameworks to ensure that agentic AI behaves in ways that are beneficial and non-threatening to humans.\n",
      "\n",
      "- **Human-AI Collaboration**: Designing systems where agentic AI can work alongside humans effectively, complementing human strengths and compensating for weaknesses.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Agentic AI represents a significant advancement in the field of artificial intelligence, moving beyond simple task execution to more autonomous and adaptable forms of intelligence. While it offers numerous potential benefits across various domains, it also presents challenges that must be carefully managed to ensure its safe and ethical integration into society. Ongoing research and interdisciplinary collaboration are essential to harness the full potential of agentic AI while mitigating its risks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "res = llm.invoke(\"what is agentic ai?\")\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Qwen model using Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, so I need to explain what generative AI is. Hmm, where do I start? I remember hearing about AI that creates images or text, like DALL-E or something. But I should be more precise. Let me think.\n",
      "\n",
      "First, maybe define what generative AI is in simple terms. It's a type of AI that can create new content, right? So, unlike other AI that might just recognize things (like identifying a cat in a photo), generative AI actually makes new stuff. But how exactly does it work?\n",
      "\n",
      "Wait, I think it uses machine learning, specifically neural networks. Maybe it's about training the model on a lot of data and then having it generate something new based on that data. Like, if you train it on lots of photos of faces, it can create a new face that looks realistic but isn't any existing person's face. That's generative adversarial networks (GANs), right? Or is that just one type?\n",
      "\n",
      "Oh, right, there are different types of generative models. GANs are one, and there's also variational autoencoders (VAEs), and maybe others like transformers used in text generation. So maybe I should mention different techniques?\n",
      "\n",
      "Also, applications. People use generative AI for art, music, writing, even in science for drug discovery. It's used in creating synthetic data for training other models, which is super useful because collecting real data is hard sometimes.\n",
      "\n",
      "But how does it actually work on a basic level? The model learns patterns from the training data. When generating new content, it tries to replicate those patterns but in a novel way. So, it's not just copying; it's making something new that's similar in style or structure.\n",
      "\n",
      "Wait, maybe I should clarify that generative AI isn't just about making images. It can be text, audio, 3D models, etc. So it's a broad field. The key is that the AI generates new data instances that are similar to the training data but not exact copies.\n",
      "\n",
      "Hmm, I should also mention some examples. Like, GPT-3 is a generative AI for text, DALL-E for images, MidJourney as well. Stable Diffusion is another one. These are popular tools that people might have heard of.\n",
      "\n",
      "Are there any challenges or limitations? Well, there's the issue of bias in the training data leading to biased outputs. There's also the problem of over-reliance on the data, so sometimes the generated content might be too similar or even copy existing works, which raises copyright issues. Plus, the ethical concerns around deepfakes and misinformation.\n",
      "\n",
      "Maybe structure the answer by starting with a definition, then how it works, types of models, common applications, examples, and then challenges. That makes sense. Let me check if I got all the key points down. Yeah, that seems comprehensive. I need to explain it clearly without getting too technical, so the user can understand even without a background in AI.\n",
      "\n",
      "Wait, also, maybe mention the difference between generative and discriminative models. Discriminative models predict outcomes (like classifying an image), while generative models model the data distribution to generate new data. That's an important distinction.\n",
      "\n",
      "Okay, putting it all together. Start with a simple definition, explain the difference from other AI types, how it's trained using machine learning, give examples of models and applications, mention common techniques like GANs and transformers, and then touch on challenges and ethical considerations. That should cover it without being too overwhelming.\n",
      "</think>\n",
      "\n",
      "**Generative AI: A Comprehensive Overview**\n",
      "\n",
      "**1. Definition:**  \n",
      "Generative AI refers to a subset of artificial intelligence that enables machines to create **new, original content** that is similar to the data they were trained on. Unlike discriminative AI (which focuses on tasks like classification or prediction), generative AI models learn patterns from existing data to produce novel outputs such as text, images, audio, or even 3D models.\n",
      "\n",
      "---\n",
      "\n",
      "**2. How It Works:**  \n",
      "- **Training Process:**  \n",
      "  Generative AI models are trained on large datasets (e.g., images, text, or sounds). During training, they learn the underlying patterns, structures, and statistical relationships in the data.  \n",
      "- **Content Generation:**  \n",
      "  Once trained, the model can generate new instances by sampling from the learned distribution. These outputs are *original* but reflect the style, themes, or characteristics of the training data.\n",
      "\n",
      "---\n",
      "\n",
      "**3. Key Techniques:**  \n",
      "Generative AI relies on advanced machine learning architectures, including:  \n",
      "- **Generative Adversarial Networks (GANs):**  \n",
      "  Two neural networks (a generator and a discriminator) compete: the generator creates content, while the discriminator evaluates its authenticity. Over time, the generator improves to produce realistic outputs.  \n",
      "- **Variational Autoencoders (VAEs):**  \n",
      "  Encode input data into a compressed representation and then decode it to generate new data.  \n",
      "- **Transformer Models:**  \n",
      "  Used heavily in text and multimodal AI (e.g., GPT-3 for text, DALL-E for text-to-image). Transformers excel at capturing long-range dependencies in data.  \n",
      "- **Diffusion Models:**  \n",
      "  Progressively denoise random noise to create coherent images (e.g., Stable Diffusion).  \n",
      "\n",
      "---\n",
      "\n",
      "**4. Applications:**  \n",
      "Generative AI is versatile and widely used across industries:  \n",
      "- **Creative Arts:**  \n",
      "  - **Text:** Writing stories, scripts, or even code (e.g., GitHub Copilot).  \n",
      "  - **Images/Art:** Creating digital art, designing logos, or editing photos (e.g., DALL-E, MidJourney).  \n",
      "  - **Music:** Composing melodies or producing background scores.  \n",
      "- **Science & Research:**  \n",
      "  - **Drug Discovery:** Generating molecular structures for potential new drugs.  \n",
      "  - **Data Synthesis:** Creating synthetic datasets to augment training data for other AI models.  \n",
      "- **Business & Marketing:**  \n",
      "  - Personalized content creation, customer service chatbots, and dynamic website design.  \n",
      "- **Entertainment:**  \n",
      "  - Video game assets, movie special effects, and virtual reality environments.  \n",
      "\n",
      "---\n",
      "\n",
      "**5. Popular Examples:**  \n",
      "- **Text Generation:** GPT-3, GPT-4, Claude.  \n",
      "- **Image Generation:** DALL-E, Stable Diffusion, MidJourney.  \n",
      "- **Multimodal AI:** Google’s Gemini, Meta’s Llama series.  \n",
      "- **Audio:** Jukedeck (music), Amazon Polly (speech synthesis).  \n",
      "\n",
      "---\n",
      "\n",
      "**6. Challenges & Considerations:**  \n",
      "- **Bias & Ethics:**  \n",
      "  - Outputs can reflect biases in training data (e.g., stereotypes in generated text or images).  \n",
      "  - Risks of misuse: deepfakes, misinformation, or copyright infringement.  \n",
      "- **Quality Control:**  \n",
      "  - Outputs may occasionally be nonsensical, unsafe, or factually incorrect.  \n",
      "- **Computational Costs:**  \n",
      "  Training large generative models requires significant computing power.  \n",
      "\n",
      "---\n",
      "\n",
      "**7. Why It Matters:**  \n",
      "Generative AI democratizes creativity and innovation by automating complex tasks. It enables artists, scientists, and businesses to explore ideas faster and at scale, though it requires careful oversight to mitigate ethical risks.\n",
      "\n",
      "In summary, generative AI is a powerful tool that empowers machines to \"imagine\" and create, but its responsible use hinges on addressing its limitations and societal impacts.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "result = model.invoke(\"what is generative ai?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Prompt\n",
    "\n",
    "#### ChatPromptTemplate is used for conversation\n",
    "#### PromptTemplate is used for single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are an AI Engineer. Provide me answer based on the given question.\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining prompt and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an AI Engineer. Provide me answer based on the given question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000015331F897D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001532922D650>, model_name='qwen-qwq-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt|model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, the user is asking for a brief explanation of LangSmith. Let me start by recalling what I know about it. LangSmith is a tool related to LangChain, right? LangChain is a framework for developing applications with language models. So, LangSmith is probably a part of that ecosystem.\n",
      "\n",
      "I remember that LangSmith is an observability and evaluation tool. It helps track and analyze LLM (Large Language Model) applications. The key features might include monitoring the performance of these applications, evaluating the quality of outputs, and maybe even comparing different models or versions.\n",
      "\n",
      "Wait, the user wants a brief overview, so I should keep it concise. Let me structure the main points: what it is, its purpose, key features, and maybe its relation to LangChain. \n",
      "\n",
      "First, define LangSmith as an observability platform designed for LangChain. Then mention that it's used to monitor and improve LLM applications. Key features would include tracking inputs, outputs, and metrics. Maybe also mention version control for models and experiments, and how it helps in debugging and optimizing applications.\n",
      "\n",
      "I should also highlight that it's part of the LangChain suite, so users who work with LangChain can use LangSmith to get insights into their applications. Maybe include use cases like comparing different prompts or models, evaluating performance over time, and ensuring the system behaves as expected.\n",
      "\n",
      "Make sure to avoid technical jargon where possible, but still be precise. Let me check if I missed any important aspects. Oh, right, it's built to handle the complexity of working with LLMs, which can have varying outputs, so having a tool to track that is essential. Alright, putting it all together in a clear, concise manner without going into too much detail.\n",
      "</think>\n",
      "\n",
      "**LangSmith** is an **observability and evaluation platform** designed for developers and teams building applications with large language models (LLMs), particularly those using the **LangChain framework**. It provides tools to monitor, analyze, and optimize LLM-based workflows. Here’s a concise overview:\n",
      "\n",
      "### **Key Features**:\n",
      "1. **Performance Tracking**:  \n",
      "   - Logs and analyzes interactions between LLMs, prompts, and user inputs/outputs.  \n",
      "   - Tracks metrics like response time, cost, and success/failure rates.\n",
      "\n",
      "2. **Experimentation & Comparison**:  \n",
      "   - Compares different versions of prompts, models, or workflows to evaluate performance.  \n",
      "   - Supports A/B testing and iterative improvements.\n",
      "\n",
      "3. **Debugging & Troubleshooting**:  \n",
      "   - Identifies errors, such as model hallucinations or unexpected outputs.  \n",
      "   - Allows filtering logs by specific criteria (e.g., user queries, model versions).\n",
      "\n",
      "4. **Version Control**:  \n",
      "   - Manages versions of models, prompts, and code to ensure reproducibility.  \n",
      "\n",
      "5. **Integration with LangChain**:  \n",
      "   - Seamlessly integrates with LangChain’s components (e.g., Chains, Agents, Prompts).  \n",
      "   - Works with various LLM providers (e.g., OpenAI, Anthropic, etc.).\n",
      "\n",
      "### **Purpose**:  \n",
      "LangSmith helps teams **build robust, reliable LLM applications** by providing visibility into model behavior, reducing costs, and improving output quality through iterative testing and optimization.\n",
      "\n",
      "**Use Case Example**: A team might use LangSmith to compare the performance of two prompts for a customer support chatbot, identifying which prompt reduces user frustration and lowers operational costs.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\":\"Tell me in brief about langsmith\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using StrOutputParser to parse the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, the user asked for the top 3 features of using Groq. Let me start by recalling what Groq is. It's a query language developed by Sanity.io, right? So I need to focus on its key features that make it stand out.\n",
      "\n",
      "First, I remember that Groq is known for its flexible and intuitive syntax. Unlike some other query languages that have rigid structures, Groq allows developers to write queries in a more natural, almost English-like way. That makes it easier to read and write, especially for complex data structures. That's probably a top feature because readability is important for maintainability.\n",
      "\n",
      "Next, another big point is performance. Since Groq is optimized for content-centric applications, it can handle large datasets efficiently. I think it uses a columnar storage format, which speeds up query processing. This would be important for applications needing quick access to content without heavy computation. That's definitely a key advantage over SQL or other languages that might not be as optimized for content delivery.\n",
      "\n",
      "Thirdly, Groq supports powerful data transformations. It allows for projecting, filtering, and shaping data into exactly the structure needed without additional processing. This reduces the need for post-processing in the application code. Features like lambda functions and array operations make it versatile for manipulating data on the fly. \n",
      "\n",
      "Wait, are there other features that might be more critical? Maybe real-time data handling or integration with specific platforms? But the user specifically asked for top 3, so sticking with the ones I have. I should also explain each point clearly, maybe give a brief example for each to make it concrete. Let me structure each feature with a heading and a description, making sure to highlight why each is a top feature. Yeah, that should cover it. Let me put it all together now.\n",
      "</think>\n",
      "\n",
      "Here are the **top 3 features of Groq** (the query language developed by **Sanity.io**), highlighting what makes it powerful and unique:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Flexible and Intuitive Syntax**  \n",
      "Groq (pronounced \"Grok\") uses a **human-readable, expression-based syntax** that mirrors natural language, making it easy to write and understand complex queries.  \n",
      "- **Key Aspects**:  \n",
      "  - `->` (the \"pipe\" operator) allows chaining operations (filter, map, sort).  \n",
      "  - `@` and `^` symbols enable referencing elements and parent contexts.  \n",
      "  - **Example**:  \n",
      "    ```groq\n",
      "    *[_type == \"post\" && author->name == \"Alice\" | order(publishedAt desc)][0...3]\n",
      "    ```  \n",
      "    This query fetches the **3 most recent posts by Alice**, ordered by publication date.  \n",
      "- **Why It Matters**: Reduces cognitive load for developers, enabling intuitive data querying even for nested or relational structures.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **High Performance for Content-Centric Data**  \n",
      "Groq is optimized for **content-centric workloads**, making it fast and efficient for querying unstructured or semi-structured data (e.g., content, CMS data, blogs).  \n",
      "- **Key Aspects**:  \n",
      "  - Leverages **columnar storage** (used in Sanity.io's database) for optimized performance.  \n",
      "  - Minimizes computation by avoiding unnecessary data fetching.  \n",
      "- **Why It Matters**: Ideal for real-time applications (e.g., blogs, e-commerce) where speed and scalability are critical.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Powerful Data Shaping and Transformation**  \n",
      "Groq allows **rich data transformations** directly in the query, eliminating the need for post-processing in application code.  \n",
      "- **Key Aspects**:  \n",
      "  - **Projection**: Define the exact output structure (e.g., include/exclude fields).  \n",
      "  - **Array Manipulation**: Filter, map, and reduce arrays natively.  \n",
      "  - **References**: Resolve relational data (e.g., `author->name` to fetch a referenced document’s field).  \n",
      "  - **Lambda Functions**: Use `_[]` for inline transformations.  \n",
      "- **Example**:  \n",
      "  ```groq\n",
      "  *[_type == \"product\"] {\n",
      "    name,\n",
      "    price,\n",
      "    category->name,\n",
      "    inStock: availability == \"inStock\"\n",
      "  }[0...10]\n",
      "  ```  \n",
      "  This returns a **formatted product list** with related category names and a simplified `inStock` boolean.  \n",
      "- **Why It Matters**: Reduces backend complexity by handling data shaping at the query layer.\n",
      "\n",
      "---\n",
      "\n",
      "### Why Use Groq?  \n",
      "Groq shines in scenarios where **content-driven applications** require:  \n",
      "- Clean, readable queries for complex data relationships.  \n",
      "- High performance for content delivery.  \n",
      "- Minimal post-processing in application logic.  \n",
      "\n",
      "It’s particularly popular in **headless CMS** setups (like Sanity.io) where content needs to be fetched and formatted efficiently.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt|model|parser\n",
    "output=chain2.invoke({\"input\":\"tell me top 3 features of using groq\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'LangSmith', 'description': \"As of my knowledge cutoff in October 2023, there is limited or no available information about 'LangSmith'. It may refer to a company, product, or service related to language technologies or another domain. For the most accurate and up-to-date information, please refer to official sources or provide additional context.\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "json_output_parser = JsonOutputParser()\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"Answer the user query \\n format the response as follows {format_instruction} \\n user query :{input}\",\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\"format_instruction\": json_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain3 = prompt_template | llm | json_output_parser\n",
    "result3 = chain3.invoke({\"input\": \"tell me about langsmith\"})\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using XMLOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```xml\\n<Langsmith>\\n    <Name>Langsmith</Name>\\n    <Description>Langsmith is a tool developed by LangChain that assists developers in monitoring, debugging, and optimizing their language models. It provides comprehensive insights and analytics to enhance the performance and reliability of AI-driven applications.</Description>\\n    <Features>\\n        <Feature>Real-time Monitoring of Language Model Performance</Feature>\\n        <Feature>Debugging Tools for Analyzing Model Outputs</Feature>\\n        <Feature>Performance Optimization Recommendations</Feature>\\n        <Feature>User-Friendly Dashboard Interface</Feature>\\n        <Feature>Integration with Various Development Environments</Feature>\\n    </Features>\\n    <UseCases>\\n        <UseCase>Improving Accuracy of Chatbots</UseCase>\\n        <UseCase>Enhancing Content Generation Systems</UseCase>\\n        <UseCase>Monitoring AI-driven Customer Support Solutions</UseCase>\\n    </UseCases>\\n    <Website>https://www.langchain.com/langsmith</Website>\\n    <Contact>\\n        <Email>support@langchain.com</Email>\\n        <Phone>+1-800-123-4567</Phone>\\n    </Contact>\\n</Langsmith>\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 895, 'prompt_tokens': 200, 'total_tokens': 1095, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 640, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_3da8b0b088', 'id': 'chatcmpl-BhFmXw5VDHyZab4J5rOxIYeIMJdCa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--d6762b31-8207-48b4-81fd-57f0bde0c054-0' usage_metadata={'input_tokens': 200, 'output_tokens': 895, 'total_tokens': 1095, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 640}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "xml_output_parser = XMLOutputParser()\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"Answer the user query \\n format the response as follows {format_instruction} \\n user query :{input}\",\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\"format_instruction\": xml_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain3 = prompt_template | llm\n",
    "result3 = chain3.invoke({\"input\": \"tell me about langsmith\"})\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': \"Why couldn't the bicycle find its way home?\", 'punchline': 'Because it lost its bearings!'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field \n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm_model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to setup a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "joke_query = \"Tell me a joke\"\n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template= \"Answer the following user query \\n {format_instruction} \\n {query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables=({\"format_instruction\":output_parser.get_format_instructions()})\n",
    ")\n",
    "\n",
    "chain = prompt | llm_model | output_parser\n",
    "result=chain.invoke({\"query\":joke_query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
